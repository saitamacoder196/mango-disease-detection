{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thử nghiệm mô hình phân đoạn bệnh trên da xoài\n",
    "\n",
    "Notebook này dùng để thử nghiệm mô hình U-Net đã được huấn luyện cho việc phân đoạn các loại bệnh trên da xoài. Mô hình có thể nhận diện 6 lớp bao gồm:\n",
    "\n",
    "1. **Background (Nền)**: Vùng không bệnh - mã màu: #000000 (đen)\n",
    "2. **Da cám (DC)**: Bệnh do nấm Colletotrichum gloeosporioides - mã màu: #FF0000 (đỏ)\n",
    "3. **Da ếch (DE)**: Bệnh do nấm và vi khuẩn kết hợp - mã màu: #00FF00 (xanh lá)\n",
    "4. **Đóm đen (DD)**: Bệnh do nấm Alternaria alternata - mã màu: #0000FF (xanh dương)\n",
    "5. **Thán thư (TT)**: Bệnh do Colletotrichum gloeosporioides - mã màu: #FFFF00 (vàng)\n",
    "6. **Rùi đụt (RD)**: Bệnh do một số loài nấm - mã màu: #FF00FF (tím)\n",
    "\n",
    "Đầu ra của mô hình sẽ là:\n",
    "- Mask phân đoạn đã được tô màu\n",
    "- Ảnh overlay (kết hợp giữa ảnh gốc và mask)\n",
    "- Phần trăm diện tích của từng loại bệnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==2.1.0 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 1)) (2.1.0)\n",
      "Collecting albumentations==0.4.6 (from -r ../requirements.txt (line 2))\n",
      "  Using cached albumentations-0.4.6-py3-none-any.whl\n",
      "Requirement already satisfied: astunparse==1.6.3 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 3)) (1.6.3)\n",
      "Collecting cachetools==5.5.2 (from -r ../requirements.txt (line 4))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting charset-normalizer==3.4.1 (from -r ../requirements.txt (line 5))\n",
      "  Using cached charset_normalizer-3.4.1-cp38-cp38-win_amd64.whl.metadata (36 kB)\n",
      "Requirement already satisfied: colorama==0.4.6 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 6)) (0.4.6)\n",
      "Collecting cycler==0.11.0 (from -r ../requirements.txt (line 7))\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting efficientnet==1.1.1 (from -r ../requirements.txt (line 8))\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting fonttools==4.38.0 (from -r ../requirements.txt (line 9))\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl.metadata (138 kB)\n",
      "Collecting gast==0.3.3 (from -r ../requirements.txt (line 10))\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-auth==2.38.0 (from -r ../requirements.txt (line 11))\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.6 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 12)) (0.4.6)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 13)) (0.2.0)\n",
      "Collecting grpcio==1.62.3 (from -r ../requirements.txt (line 14))\n",
      "  Downloading grpcio-1.62.3-cp38-cp38-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: h5py==2.10.0 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 15)) (2.10.0)\n",
      "Requirement already satisfied: idna==3.10 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 16)) (3.10)\n",
      "Collecting image-classifiers==0.2.0 (from -r ../requirements.txt (line 17))\n",
      "  Downloading image_classifiers-0.2.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting imageio==2.31.2 (from -r ../requirements.txt (line 18))\n",
      "  Downloading imageio-2.31.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting imgaug==0.4.0 (from -r ../requirements.txt (line 19))\n",
      "  Using cached imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting importlib-metadata==6.7.0 (from -r ../requirements.txt (line 20))\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting joblib==1.3.2 (from -r ../requirements.txt (line 21))\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting keras==2.11.0 (from -r ../requirements.txt (line 22))\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: Keras-Applications==1.0.8 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 23)) (1.0.8)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.2 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 24)) (1.1.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.5 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 25)) (1.4.5)\n",
      "Collecting Markdown==3.4.4 (from -r ../requirements.txt (line 26))\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: MarkupSafe==2.1.5 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 27)) (2.1.5)\n",
      "Collecting matplotlib==3.5.3 (from -r ../requirements.txt (line 28))\n",
      "  Downloading matplotlib-3.5.3-cp38-cp38-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting networkx==2.6.3 (from -r ../requirements.txt (line 29))\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting numpy==1.18.5 (from -r ../requirements.txt (line 30))\n",
      "  Using cached numpy-1.18.5-cp38-cp38-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 31)) (3.2.2)\n",
      "Collecting opencv-python==4.4.0.46 (from -r ../requirements.txt (line 32))\n",
      "  Downloading opencv_python-4.4.0.46-cp38-cp38-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: opencv-python-headless==4.11.0.86 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 33)) (4.11.0.86)\n",
      "Collecting opt-einsum==3.3.0 (from -r ../requirements.txt (line 34))\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting packaging==24.0 (from -r ../requirements.txt (line 35))\n",
      "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting Pillow==9.5.0 (from -r ../requirements.txt (line 36))\n",
      "  Using cached Pillow-9.5.0-cp38-cp38-win_amd64.whl.metadata (9.7 kB)\n",
      "Collecting protobuf==3.20.3 (from -r ../requirements.txt (line 37))\n",
      "  Using cached protobuf-3.20.3-cp38-cp38-win_amd64.whl.metadata (699 bytes)\n",
      "Collecting pyasn1==0.5.1 (from -r ../requirements.txt (line 38))\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyasn1-modules==0.3.0 (from -r ../requirements.txt (line 39))\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pyparsing==3.1.4 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 40)) (3.1.4)\n",
      "Collecting python-dateutil==2.9.0.post0 (from -r ../requirements.txt (line 41))\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting PyWavelets==1.3.0 (from -r ../requirements.txt (line 42))\n",
      "  Downloading PyWavelets-1.3.0-cp38-cp38-win_amd64.whl.metadata (1.9 kB)\n",
      "Collecting PyYAML==6.0.1 (from -r ../requirements.txt (line 43))\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests==2.31.0 (from -r ../requirements.txt (line 44))\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: requests-oauthlib==2.0.0 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 45)) (2.0.0)\n",
      "Requirement already satisfied: rsa==4.9 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 46)) (4.9)\n",
      "Collecting scikit-image==0.19.3 (from -r ../requirements.txt (line 47))\n",
      "  Downloading scikit_image-0.19.3-cp38-cp38-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting scikit-learn==1.0.2 (from -r ../requirements.txt (line 48))\n",
      "  Downloading scikit_learn-1.0.2-cp38-cp38-win_amd64.whl.metadata (10 kB)\n",
      "Collecting scipy==1.4.1 (from -r ../requirements.txt (line 49))\n",
      "  Using cached scipy-1.4.1-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting segmentation-models==0.2.1 (from -r ../requirements.txt (line 50))\n",
      "  Downloading segmentation_models-0.2.1-py2.py3-none-any.whl.metadata (841 bytes)\n",
      "Collecting shapely==2.0.7 (from -r ../requirements.txt (line 51))\n",
      "  Using cached shapely-2.0.7-cp38-cp38-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting six==1.17.0 (from -r ../requirements.txt (line 52))\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorboard==2.11.2 (from -r ../requirements.txt (line 53))\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: tensorboard-data-server==0.6.1 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 54)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 55)) (1.8.1)\n",
      "Collecting tensorflow==2.3.0 (from -r ../requirements.txt (line 56))\n",
      "  Using cached tensorflow-2.3.0-cp38-cp38-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-estimator==2.3.0 (from -r ../requirements.txt (line 57))\n",
      "  Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting termcolor==2.3.0 (from -r ../requirements.txt (line 58))\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting threadpoolctl==3.1.0 (from -r ../requirements.txt (line 59))\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting tifffile==2021.11.2 (from -r ../requirements.txt (line 60))\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 61)) (4.67.1)\n",
      "Collecting typing_extensions==4.7.1 (from -r ../requirements.txt (line 62))\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting urllib3==2.0.7 (from -r ../requirements.txt (line 63))\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting Werkzeug==2.2.3 (from -r ../requirements.txt (line 64))\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting wincertstore==0.2 (from -r ../requirements.txt (line 65))\n",
      "  Downloading wincertstore-0.2-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: wrapt==1.16.0 in e:\\conda_envs\\mango-env\\lib\\site-packages (from -r ../requirements.txt (line 66)) (1.16.0)\n",
      "Collecting zipp==3.15.0 (from -r ../requirements.txt (line 67))\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\conda_envs\\mango-env\\lib\\site-packages (from requests==2.31.0->-r ../requirements.txt (line 44)) (2024.8.30)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\conda_envs\\mango-env\\lib\\site-packages (from tensorboard==2.11.2->-r ../requirements.txt (line 53)) (75.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\conda_envs\\mango-env\\lib\\site-packages (from tensorboard==2.11.2->-r ../requirements.txt (line 53)) (0.44.0)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp38-cp38-win_amd64.whl (102 kB)\n",
      "Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "   ---------------------------------------- 0.0/965.4 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 786.4/965.4 kB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 786.4/965.4 kB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 965.4/965.4 kB 1.3 MB/s eta 0:00:00\n",
      "Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading grpcio-1.62.3-cp38-cp38-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.0/3.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.0/3.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.0/3.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.0/3.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.8/3.7 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.1/3.7 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.1/3.7 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.1/3.7 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.1/3.7 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.7 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading image_classifiers-0.2.0-py2.py3-none-any.whl (76 kB)\n",
      "Downloading imageio-2.31.2-py3-none-any.whl (313 kB)\n",
      "Using cached imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Downloading matplotlib-3.5.3-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "   ---------------------------------------- 0.0/7.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/7.2 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.1/7.2 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.1/7.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.2/7.2 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.8/7.2 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.8/7.2 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.2/7.2 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 1.3/1.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 6.3 MB/s eta 0:00:00\n",
      "Using cached numpy-1.18.5-cp38-cp38-win_amd64.whl (12.8 MB)\n",
      "Downloading opencv_python-4.4.0.46-cp38-cp38-win_amd64.whl (33.5 MB)\n",
      "   ---------------------------------------- 0.0/33.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/33.5 MB 5.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.8/33.5 MB 4.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.6/33.5 MB 4.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.4/33.5 MB 4.1 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 4.5/33.5 MB 4.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 5.2/33.5 MB 3.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 6.0/33.5 MB 4.0 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 7.1/33.5 MB 4.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 7.9/33.5 MB 4.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 8.4/33.5 MB 4.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 8.7/33.5 MB 3.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 9.4/33.5 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 10.5/33.5 MB 3.7 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 11.3/33.5 MB 3.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 12.1/33.5 MB 3.7 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 13.1/33.5 MB 3.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 14.2/33.5 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 15.2/33.5 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 16.0/33.5 MB 3.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 17.0/33.5 MB 3.9 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 18.1/33.5 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 18.9/33.5 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 19.7/33.5 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 20.7/33.5 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 22.0/33.5 MB 4.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 23.1/33.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 24.1/33.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 24.9/33.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 26.0/33.5 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 27.0/33.5 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 28.0/33.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 29.1/33.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 29.9/33.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 30.9/33.5 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 32.0/33.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  33.0/33.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  33.3/33.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 33.5/33.5 MB 4.0 MB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Using cached Pillow-9.5.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "Using cached protobuf-3.20.3-cp38-cp38-win_amd64.whl (904 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading PyWavelets-1.3.0-cp38-cp38-win_amd64.whl (4.2 MB)\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.8/4.2 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.1/4.2 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.4/4.2 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.2/4.2 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp38-cp38-win_amd64.whl (157 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading scikit_image-0.19.3-cp38-cp38-win_amd64.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.2 MB 6.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.2 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.2 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.2 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.3/12.2 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.8/12.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.2 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.2 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.4/12.2 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.7/12.2 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.8/12.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.0.2-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "   ---------------------------------------- 0.0/7.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/7.2 MB 3.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.6/7.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.4/7.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.1/7.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.2/7.2 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.0/7.2 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.0/7.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.8/7.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.2/7.2 MB 3.8 MB/s eta 0:00:00\n",
      "Using cached scipy-1.4.1-cp38-cp38-win_amd64.whl (31.0 MB)\n",
      "Downloading segmentation_models-0.2.1-py2.py3-none-any.whl (44 kB)\n",
      "Using cached shapely-2.0.7-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Using cached tensorflow-2.3.0-cp38-cp38-win_amd64.whl (342.5 MB)\n",
      "Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Downloading wincertstore-0.2-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Installing collected packages: wincertstore, tensorflow-estimator, zipp, Werkzeug, urllib3, typing_extensions, threadpoolctl, termcolor, six, PyYAML, pyasn1, protobuf, Pillow, packaging, numpy, networkx, keras, joblib, grpcio, gast, fonttools, cycler, charset-normalizer, cachetools, tifffile, shapely, scipy, requests, PyWavelets, python-dateutil, pyasn1-modules, opt-einsum, opencv-python, importlib-metadata, imageio, image-classifiers, scikit-learn, scikit-image, matplotlib, Markdown, google-auth, segmentation-models, imgaug, efficientnet, tensorboard, albumentations, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.13.0\n",
      "    Uninstalling tensorflow-estimator-2.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.21.0\n",
      "    Uninstalling zipp-3.21.0:\n",
      "      Successfully uninstalled zipp-3.21.0\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 3.0.6\n",
      "    Uninstalling Werkzeug-3.0.6:\n",
      "      Successfully uninstalled Werkzeug-3.0.6\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.5.0\n",
      "    Uninstalling threadpoolctl-3.5.0:\n",
      "      Successfully uninstalled threadpoolctl-3.5.0\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.4.0\n",
      "    Uninstalling termcolor-2.4.0:\n",
      "      Successfully uninstalled termcolor-2.4.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.6.1\n",
      "    Uninstalling pyasn1-0.6.1:\n",
      "      Successfully uninstalled pyasn1-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.1\n",
      "    Uninstalling networkx-3.1:\n",
      "      Successfully uninstalled networkx-3.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.51.1\n",
      "    Uninstalling grpcio-1.51.1:\n",
      "      Successfully uninstalled grpcio-1.51.1\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.53.1\n",
      "    Uninstalling fonttools-4.53.1:\n",
      "      Successfully uninstalled fonttools-4.53.1\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.12.1\n",
      "    Uninstalling cycler-0.12.1:\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.0\n",
      "    Uninstalling charset-normalizer-3.4.0:\n",
      "      Successfully uninstalled charset-normalizer-3.4.0\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.5.0\n",
      "    Uninstalling cachetools-5.5.0:\n",
      "      Successfully uninstalled cachetools-5.5.0\n",
      "  Attempting uninstall: tifffile\n",
      "    Found existing installation: tifffile 2023.7.10\n",
      "    Uninstalling tifffile-2023.7.10:\n",
      "      Successfully uninstalled tifffile-2023.7.10\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: PyWavelets\n",
      "    Found existing installation: PyWavelets 1.4.1\n",
      "    Uninstalling PyWavelets-1.4.1:\n",
      "      Successfully uninstalled PyWavelets-1.4.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0\n",
      "    Uninstalling python-dateutil-2.9.0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0\n",
      "  Attempting uninstall: pyasn1-modules\n",
      "    Found existing installation: pyasn1_modules 0.4.1\n",
      "    Uninstalling pyasn1_modules-0.4.1:\n",
      "      Successfully uninstalled pyasn1_modules-0.4.1\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt_einsum 3.4.0\n",
      "    Uninstalling opt_einsum-3.4.0:\n",
      "      Successfully uninstalled opt_einsum-3.4.0\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: uninstall-no-record-file\n",
      "\n",
      "× Cannot uninstall opencv-python 4.7.0\n",
      "╰─> The package's contents are unknown: no RECORD file was found for opencv-python.\n",
      "\n",
      "hint: The package was installed by conda. You should check if it can uninstall the package.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32me:\\conda_envs\\mango-env\\lib\\site-packages\\matplotlib\\__init__.py:129\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32me:\\conda_envs\\mango-env\\lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32me:\\conda_envs\\mango-env\\lib\\site-packages\\matplotlib\\colors.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32me:\\conda_envs\\mango-env\\lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32me:\\conda_envs\\mango-env\\lib\\site-packages\\matplotlib\\ticker.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32me:\\conda_envs\\mango-env\\lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import glob\n",
    "from tensorflow.keras.models import load_model\n",
    "import segmentation_models as sm\n",
    "\n",
    "# Kiểm tra phiên bản các thư viện\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Segmentation Models version: {sm.__version__ if hasattr(sm, '__version__') else 'Unknown'}\")\n",
    "\n",
    "# Thiết lập seed để kết quả có tính lặp lại\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Màu cho các lớp (RGB)\n",
    "CLASS_NAMES = [\"background\", \"da_cam\", \"da_ech\", \"dom_den\", \"than_thu\", \"rui_dut\"]\n",
    "COLORS = [\n",
    "    [0, 0, 0],      # Background - đen\n",
    "    [255, 0, 0],    # Da cám - đỏ\n",
    "    [0, 255, 0],    # Da ếch - xanh lá\n",
    "    [0, 0, 255],    # Đóm đen - xanh dương\n",
    "    [255, 255, 0],  # Thán thư - vàng\n",
    "    [255, 0, 255]   # Rùi đụt - tím\n",
    "]\n",
    "\n",
    "def create_colored_mask(mask):\n",
    "    \"\"\"Tạo mask màu từ mask grayscale.\"\"\"\n",
    "    colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "    for class_idx, color in enumerate(COLORS):\n",
    "        colored_mask[mask == class_idx] = color\n",
    "    return colored_mask\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"Đọc file cấu hình.\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "def load_segmentation_model(model_path):\n",
    "    \"\"\"Tải mô hình phân đoạn.\"\"\"\n",
    "    model = load_model(\n",
    "        model_path,\n",
    "        custom_objects={\n",
    "            'iou_score': sm.metrics.IOUScore(threshold=0.5),\n",
    "            'f1-score': sm.metrics.FScore(threshold=0.5)\n",
    "        }\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def predict_segmentation(model, image_path, img_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Dự đoán phân đoạn cho một ảnh.\n",
    "    \n",
    "    Args:\n",
    "        model: Mô hình đã huấn luyện\n",
    "        image_path: Đường dẫn đến ảnh cần dự đoán\n",
    "        img_size: Kích thước ảnh đầu vào\n",
    "        \n",
    "    Returns:\n",
    "        img_resized: Ảnh gốc đã resize\n",
    "        pred_mask: Mask dự đoán\n",
    "        colored_mask: Mask màu\n",
    "        overlay_img: Ảnh overlay\n",
    "        class_areas: Phần trăm diện tích từng loại bệnh\n",
    "    \"\"\"\n",
    "    # Đọc ảnh\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Không thể đọc ảnh từ {image_path}\")\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize ảnh\n",
    "    img_resized = cv2.resize(img, img_size)\n",
    "    \n",
    "    # Chuẩn bị đầu vào\n",
    "    img_input = img_resized / 255.0\n",
    "    img_input = np.expand_dims(img_input, axis=0)\n",
    "    \n",
    "    # Dự đoán\n",
    "    pred = model.predict(img_input)[0]\n",
    "    pred_mask = np.argmax(pred, axis=-1)\n",
    "    \n",
    "    # Tạo mask màu\n",
    "    colored_mask = create_colored_mask(pred_mask)\n",
    "    \n",
    "    # Tạo overlay\n",
    "    alpha = 0.6\n",
    "    overlay_img = cv2.addWeighted(img_resized, 1-alpha, colored_mask, alpha, 0)\n",
    "    \n",
    "    # Tính phần trăm diện tích từng loại bệnh\n",
    "    total_pixels = pred_mask.size\n",
    "    class_areas = {}\n",
    "    \n",
    "    for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "        pixel_count = np.sum(pred_mask == class_idx)\n",
    "        percentage = (pixel_count / total_pixels) * 100\n",
    "        class_areas[class_name] = percentage\n",
    "    \n",
    "    return img_resized, pred_mask, colored_mask, overlay_img, class_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cảnh báo: Không tìm thấy mô hình tại models/unet_model.h5\n",
      "Cảnh báo: Không tìm thấy file cấu hình tại configs/segmentation_config_new.yaml\n",
      "Cảnh báo: Không tìm thấy thư mục ảnh test tại data/segmentation/test/images\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn đến mô hình đã huấn luyện\n",
    "MODEL_PATH = 'models/unet_model.h5'  # Thay đổi nếu cần\n",
    "\n",
    "# Đường dẫn đến file cấu hình\n",
    "CONFIG_PATH = 'configs/segmentation_config_new.yaml'  # Thay đổi nếu cần\n",
    "\n",
    "# Đường dẫn đến thư mục chứa ảnh test\n",
    "TEST_DIR = 'data/segmentation/test/images'  # Thay đổi nếu cần\n",
    "\n",
    "# Kiểm tra sự tồn tại của các file và thư mục\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"Cảnh báo: Không tìm thấy mô hình tại {MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"Đã tìm thấy mô hình tại {MODEL_PATH}\")\n",
    "\n",
    "if not os.path.exists(CONFIG_PATH):\n",
    "    print(f\"Cảnh báo: Không tìm thấy file cấu hình tại {CONFIG_PATH}\")\n",
    "else:\n",
    "    print(f\"Đã tìm thấy file cấu hình tại {CONFIG_PATH}\")\n",
    "\n",
    "if not os.path.exists(TEST_DIR):\n",
    "    print(f\"Cảnh báo: Không tìm thấy thư mục ảnh test tại {TEST_DIR}\")\n",
    "else:\n",
    "    image_files = [f for f in os.listdir(TEST_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"Đã tìm thấy {len(image_files)} ảnh trong thư mục test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Tải file cấu hình\n",
    "    config = load_config(CONFIG_PATH)\n",
    "    print(\"Đã tải file cấu hình thành công\")\n",
    "    \n",
    "    # Lấy thông tin từ config\n",
    "    img_size = tuple(config['model']['input_shape'][:2])\n",
    "    num_classes = config['model']['num_classes']\n",
    "    class_names = config['model']['class_names']\n",
    "    \n",
    "    print(f\"Kích thước ảnh: {img_size}\")\n",
    "    print(f\"Số lớp: {num_classes}\")\n",
    "    print(f\"Tên các lớp: {class_names}\")\n",
    "    \n",
    "    # Tải mô hình\n",
    "    model = load_segmentation_model(MODEL_PATH)\n",
    "    print(\"Đã tải mô hình thành công\")\n",
    "    \n",
    "    # Hiển thị tóm tắt mô hình\n",
    "    model.summary()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải mô hình hoặc cấu hình: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy một số ảnh mẫu\n",
    "test_images = glob.glob(os.path.join(TEST_DIR, '*.jpg')) + \\\n",
    "             glob.glob(os.path.join(TEST_DIR, '*.jpeg')) + \\\n",
    "             glob.glob(os.path.join(TEST_DIR, '*.png'))\n",
    "\n",
    "# Chọn ngẫu nhiên một số ảnh (tối đa 5 ảnh)\n",
    "num_samples = min(5, len(test_images))\n",
    "sample_images = np.random.choice(test_images, num_samples, replace=False)\n",
    "\n",
    "# Dự đoán và hiển thị kết quả\n",
    "for image_path in sample_images:\n",
    "    try:\n",
    "        # Dự đoán\n",
    "        img, pred_mask, colored_mask, overlay, class_areas = predict_segmentation(\n",
    "            model, image_path, img_size=img_size\n",
    "        )\n",
    "        \n",
    "        # Hiển thị kết quả\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Ảnh gốc\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Ảnh gốc\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Mask dự đoán\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(colored_mask)\n",
    "        plt.title(\"Mask phân đoạn\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.imshow(overlay)\n",
    "        plt.title(\"Overlay\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Phần trăm diện tích\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Phần trăm diện tích\")\n",
    "        \n",
    "        # Hiển thị phần trăm diện tích bằng biểu đồ ngang\n",
    "        # Sắp xếp theo thứ tự giảm dần\n",
    "        sorted_areas = sorted(class_areas.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Lọc các lớp có diện tích > 0\n",
    "        filtered_areas = [(name, pct) for name, pct in sorted_areas if pct > 0]\n",
    "        \n",
    "        if filtered_areas:\n",
    "            names = [name for name, _ in filtered_areas]\n",
    "            percentages = [pct for _, pct in filtered_areas]\n",
    "            colors = [COLORS[CLASS_NAMES.index(name)] for name, _ in filtered_areas]\n",
    "            # Chuyển từ RGB sang định dạng màu của matplotlib\n",
    "            colors = [[r/255, g/255, b/255] for r, g, b in colors]\n",
    "            \n",
    "            y_pos = np.arange(len(names))\n",
    "            plt.barh(y_pos, percentages, color=colors)\n",
    "            plt.yticks(y_pos, names)\n",
    "            for i, v in enumerate(percentages):\n",
    "                plt.text(v + 0.5, i, f\"{v:.2f}%\", va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"Phân đoạn bệnh trên da xoài - {os.path.basename(image_path)}\", fontsize=16)\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "        \n",
    "        # In phần trăm diện tích cho từng loại bệnh\n",
    "        print(f\"\\nPhân tích ảnh: {os.path.basename(image_path)}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Phần trăm diện tích từng loại bệnh:\")\n",
    "        for class_name, percentage in sorted_areas:\n",
    "            if percentage > 0:\n",
    "                print(f\"{class_name}: {percentage:.2f}%\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi xử lý ảnh {image_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, test_dir, mask_dir, img_size=(512, 512), num_classes=6):\n",
    "    \"\"\"\n",
    "    Đánh giá mô hình trên tập test.\n",
    "    \n",
    "    Args:\n",
    "        model: Mô hình đã huấn luyện\n",
    "        test_dir: Thư mục chứa ảnh test\n",
    "        mask_dir: Thư mục chứa mask thực tế\n",
    "        img_size: Kích thước ảnh đầu vào\n",
    "        num_classes: Số lớp phân đoạn\n",
    "        \n",
    "    Returns:\n",
    "        metrics_per_class: Dict chứa các metrics cho từng lớp\n",
    "        avg_metrics: Dict chứa các metrics trung bình\n",
    "    \"\"\"\n",
    "    # Lấy danh sách file ảnh\n",
    "    image_files = sorted(glob.glob(os.path.join(test_dir, '*.jpg')) + \n",
    "                        glob.glob(os.path.join(test_dir, '*.jpeg')) + \n",
    "                        glob.glob(os.path.join(test_dir, '*.png')))\n",
    "    \n",
    "    # Khởi tạo metrics\n",
    "    class_iou = {class_name: [] for class_name in CLASS_NAMES}\n",
    "    class_dice = {class_name: [] for class_name in CLASS_NAMES}\n",
    "    pixel_acc = []\n",
    "    \n",
    "    # Xử lý từng ảnh\n",
    "    for image_path in image_files:\n",
    "        # Lấy tên file\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        mask_path = os.path.join(mask_dir, f\"{base_name}.png\")\n",
    "        \n",
    "        # Kiểm tra xem mask có tồn tại không\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Không tìm thấy mask cho ảnh {base_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Đọc ảnh và mask\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        \n",
    "        true_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        true_mask = cv2.resize(true_mask, img_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Dự đoán\n",
    "        img_input = img / 255.0\n",
    "        img_input = np.expand_dims(img_input, axis=0)\n",
    "        \n",
    "        pred = model.predict(img_input)[0]\n",
    "        pred_mask = np.argmax(pred, axis=-1)\n",
    "        \n",
    "        # Tính pixel accuracy\n",
    "        accuracy = np.mean(pred_mask == true_mask)\n",
    "        pixel_acc.append(accuracy)\n",
    "        \n",
    "        # Tính IoU và Dice cho từng lớp\n",
    "        for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "            # Tạo mask nhị phân cho lớp\n",
    "            true_binary = (true_mask == class_idx).astype(np.uint8)\n",
    "            pred_binary = (pred_mask == class_idx).astype(np.uint8)\n",
    "            \n",
    "            # Tính intersection và union\n",
    "            intersection = np.logical_and(true_binary, pred_binary).sum()\n",
    "            union = np.logical_or(true_binary, pred_binary).sum()\n",
    "            \n",
    "            # IoU\n",
    "            iou = intersection / union if union > 0 else 0\n",
    "            class_iou[class_name].append(iou)\n",
    "            \n",
    "            # Dice\n",
    "            dice = 2 * intersection / (true_binary.sum() + pred_binary.sum()) if (true_binary.sum() + pred_binary.sum()) > 0 else 0\n",
    "            class_dice[class_name].append(dice)\n",
    "    \n",
    "    # Tính trung bình cho các metrics\n",
    "    avg_iou = {class_name: np.mean(scores) if scores else 0 for class_name, scores in class_iou.items()}\n",
    "    avg_dice = {class_name: np.mean(scores) if scores else 0 for class_name, scores in class_dice.items()}\n",
    "    avg_pixel_acc = np.mean(pixel_acc) if pixel_acc else 0\n",
    "    \n",
    "    # Tính trung bình tổng thể\n",
    "    mean_iou = np.mean([iou for iou in avg_iou.values() if iou > 0])\n",
    "    mean_dice = np.mean([dice for dice in avg_dice.values() if dice > 0])\n",
    "    \n",
    "    # Đóng gói kết quả\n",
    "    metrics_per_class = {\n",
    "        'iou': avg_iou,\n",
    "        'dice': avg_dice\n",
    "    }\n",
    "    \n",
    "    avg_metrics = {\n",
    "        'mean_iou': mean_iou,\n",
    "        'mean_dice': mean_dice,\n",
    "        'pixel_accuracy': avg_pixel_acc\n",
    "    }\n",
    "    \n",
    "    return metrics_per_class, avg_metrics\n",
    "\n",
    "# Thư mục chứa mask thực tế\n",
    "MASK_DIR = 'data/segmentation/test/masks'  # Thay đổi nếu cần\n",
    "\n",
    "if os.path.exists(TEST_DIR) and os.path.exists(MASK_DIR):\n",
    "    try:\n",
    "        # Đánh giá mô hình\n",
    "        print(\"Đang đánh giá mô hình trên tập test...\")\n",
    "        metrics_per_class, avg_metrics = evaluate_on_test_set(\n",
    "            model, TEST_DIR, MASK_DIR, img_size=img_size, num_classes=num_classes\n",
    "        )\n",
    "        \n",
    "        # Hiển thị kết quả trung bình\n",
    "        print(\"\\nKết quả đánh giá trung bình:\")\n",
    "        print(f\"Mean IoU: {avg_metrics['mean_iou']:.4f}\")\n",
    "        print(f\"Mean Dice: {avg_metrics['mean_dice']:.4f}\")\n",
    "        print(f\"Pixel Accuracy: {avg_metrics['pixel_accuracy']:.4f}\")\n",
    "        \n",
    "        # Hiển thị kết quả cho từng lớp\n",
    "        print(\"\\nKết quả đánh giá cho từng lớp:\")\n",
    "        \n",
    "        # Tạo bảng để hiển thị kết quả\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        # Biểu đồ IoU\n",
    "        plt.subplot(1, 2, 1)\n",
    "        classes = list(metrics_per_class['iou'].keys())\n",
    "        iou_values = list(metrics_per_class['iou'].values())\n",
    "        colors = [[r/255, g/255, b/255] for r, g, b in COLORS]\n",
    "        \n",
    "        bars = plt.bar(classes, iou_values, color=colors)\n",
    "        plt.title('IoU Score cho từng lớp')\n",
    "        plt.xlabel('Lớp')\n",
    "        plt.ylabel('IoU Score')\n",
    "        plt.ylim([0, 1])\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Thêm giá trị lên đầu mỗi cột\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Biểu đồ Dice\n",
    "        plt.subplot(1, 2, 2)\n",
    "        dice_values = list(metrics_per_class['dice'].values())\n",
    "        \n",
    "        bars = plt.bar(classes, dice_values, color=colors)\n",
    "        plt.title('Dice Score cho từng lớp')\n",
    "        plt.xlabel('Lớp')\n",
    "        plt.ylabel('Dice Score')\n",
    "        plt.ylim([0, 1])\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Thêm giá trị lên đầu mỗi cột\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # In kết quả dưới dạng bảng\n",
    "        print(\"\\nIoU Score và Dice Score cho từng lớp:\")\n",
    "        print(f\"{'Lớp':<15} {'IoU':<10} {'Dice':<10}\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        for class_name in CLASS_NAMES:\n",
    "            iou = metrics_per_class['iou'][class_name]\n",
    "            dice = metrics_per_class['dice'][class_name]\n",
    "            print(f\"{class_name:<15} {iou:.4f}{'':6} {dice:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đánh giá mô hình: {e}\")\n",
    "else:\n",
    "    print(\"Không tìm thấy thư mục test hoặc thư mục mask để đánh giá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "def predict_on_uploaded_image(model, uploaded_file, img_size=(512, 512)):\n",
    "    \"\"\"Dự đoán phân đoạn trên ảnh tải lên.\"\"\"\n",
    "    # Đọc ảnh từ file tải lên\n",
    "    content = uploaded_file.read()\n",
    "    img = Image.open(io.BytesIO(content))\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Chuyển sang RGB nếu ảnh là RGBA\n",
    "    if img.shape[-1] == 4:\n",
    "        img = img[:, :, :3]\n",
    "    \n",
    "    # Resize ảnh\n",
    "    img_resized = cv2.resize(img, img_size)\n",
    "    \n",
    "    # Chuẩn bị đầu vào\n",
    "    img_input = img_resized / 255.0\n",
    "    img_input = np.expand_dims(img_input, axis=0)\n",
    "    \n",
    "    # Dự đoán\n",
    "    pred = model.predict(img_input)[0]\n",
    "    pred_mask = np.argmax(pred, axis=-1)\n",
    "    \n",
    "    # Tạo mask màu\n",
    "    colored_mask = create_colored_mask(pred_mask)\n",
    "    \n",
    "    # Tạo overlay\n",
    "    alpha = 0.6\n",
    "    overlay_img = cv2.addWeighted(img_resized, 1-alpha, colored_mask, alpha, 0)\n",
    "    \n",
    "    # Tính phần trăm diện tích từng loại bệnh\n",
    "    total_pixels = pred_mask.size\n",
    "    class_areas = {}\n",
    "    \n",
    "    for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "        pixel_count = np.sum(pred_mask == class_idx)\n",
    "        percentage = (pixel_count / total_pixels) * 100\n",
    "        class_areas[class_name] = percentage\n",
    "    \n",
    "    return img_resized, pred_mask, colored_mask, overlay_img, class_areas\n",
    "\n",
    "# Tải lên ảnh\n",
    "print(\"Tải lên ảnh để thử nghiệm:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Xử lý từng ảnh được tải lên\n",
    "for filename, content in uploaded.items():\n",
    "    try:\n",
    "        # Lưu file tạm thời\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        # Mở file để dự đoán\n",
    "        with open(filename, 'rb') as f:\n",
    "            img, pred_mask, colored_mask, overlay, class_areas = predict_on_uploaded_image(\n",
    "                model, f, img_size=img_size\n",
    "            )\n",
    "        \n",
    "        # Hiển thị kết quả (tương tự như cell 6)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Ảnh gốc\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Ảnh gốc\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Mask dự đoán\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(colored_mask)\n",
    "        plt.title(\"Mask phân đoạn\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.imshow(overlay)\n",
    "        plt.title(\"Overlay\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Phần trăm diện tích\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Phần trăm diện tích\")\n",
    "        \n",
    "        # Hiển thị phần trăm diện tích bằng biểu đồ ngang\n",
    "        sorted_areas = sorted(class_areas.items(), key=lambda x: x[1], reverse=True)\n",
    "        filtered_areas = [(name, pct) for name, pct in sorted_areas if pct > 0]\n",
    "        \n",
    "        if filtered_areas:\n",
    "            names = [name for name, _ in filtered_areas]\n",
    "            percentages = [pct for _, pct in filtered_areas]\n",
    "            colors = [COLORS[CLASS_NAMES.index(name)] for name, _ in filtered_areas]\n",
    "            colors = [[r/255, g/255, b/255] for r, g, b in colors]\n",
    "            \n",
    "            y_pos = np.arange(len(names))\n",
    "            plt.barh(y_pos, percentages, color=colors)\n",
    "            plt.yticks(y_pos, names)\n",
    "            for i, v in enumerate(percentages):\n",
    "                plt.text(v + 0.5, i, f\"{v:.2f}%\", va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"Phân đoạn bệnh trên da xoài - {filename}\", fontsize=16)\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "        \n",
    "        # In phần trăm diện tích cho từng loại bệnh\n",
    "        print(f\"\\nPhân tích ảnh: {filename}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Phần trăm diện tích từng loại bệnh:\")\n",
    "        for class_name, percentage in sorted_areas:\n",
    "            if percentage > 0:\n",
    "                print(f\"{class_name}: {percentage:.2f}%\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Xóa file tạm\n",
    "        os.remove(filename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi xử lý ảnh {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết luận\n",
    "\n",
    "Mô hình phân đoạn U-Net đã thành công trong việc nhận diện và phân đoạn các loại bệnh khác nhau trên da xoài. Kết quả cho thấy:\n",
    "\n",
    "1. **Độ chính xác**: Mô hình thể hiện khả năng phân đoạn tốt với các loại bệnh khác nhau, với độ chính xác pixel, IoU và Dice Score ở mức chấp nhận được.\n",
    "\n",
    "2. **Phân biệt các loại bệnh**: Mô hình có thể phân biệt rõ ràng giữa các loại bệnh khác nhau trên cùng một quả xoài, từ đó giúp đánh giá mức độ nghiêm trọng của từng loại bệnh.\n",
    "\n",
    "3. **Phân tích định lượng**: Việc tính toán phần trăm diện tích từng loại bệnh cung cấp thông tin định lượng để đánh giá mức độ nhiễm bệnh của quả xoài.\n",
    "\n",
    "4. **Ứng dụng thực tế**: Mô hình này có thể được tích hợp vào các ứng dụng di động hoặc hệ thống web để phân tích bệnh trên da xoài, giúp nông dân và các chuyên gia nông nghiệp đưa ra quyết định kịp thời.\n",
    "\n",
    "Để cải thiện hơn nữa, mô hình có thể được huấn luyện với nhiều dữ liệu hơn, áp dụng thêm các kỹ thuật tăng cường dữ liệu, và thử nghiệm với các kiến trúc phân đoạn mới như DeepLabV3+, HRNet, hoặc TransUNet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mango-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
